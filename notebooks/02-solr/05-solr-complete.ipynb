{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTR Case Study: Solr\n",
    "\n",
    "Before doing this, we need to have Solr running. We downloaded a fresh solr-7.4.0 distribution from [the Solr download site](http://archive.apache.org/dist/lucene/solr/7.4.0/). Start Solr with the following command.\n",
    "\n",
    "    cd <solr_home>\n",
    "    bin/solr start\n",
    "    \n",
    "The case study follows the steps outlined in the [Solr LTR Tutorial](https://github.com/airalcorn2/Solr-LTR) and Michael Alcorn's tutorial [From Zero to Learning to Rank in Apache Solr](https://github.com/airalcorn2/Solr-LTR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import sqlite3\n",
    "import sys\n",
    "import urllib\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "\n",
    "MOVIES_DATA = os.path.join(DATA_DIR, \"movies_metadata.csv\")\n",
    "LOOKUPS_DB = os.path.join(DATA_DIR, \"lookups.db\")\n",
    "FEATURE_FILE_TEMPLATE = os.path.join(DATA_DIR, \"solr_features_{:s}.txt\")\n",
    "\n",
    "RANKLIB_LM_MODEL = os.path.join(DATA_DIR, \"solr_lambdamart_model.txt\")\n",
    "RANKLIB_PROC_LM_MODEL = os.path.join(DATA_DIR, \"solr_lambdamart_model.xml\")\n",
    "SOLR_LM_MODEL = os.path.join(DATA_DIR, \"solr_lambdamart_model.json\")\n",
    "\n",
    "SOLR_URL = \"http://localhost:8983/solr/tmdbindex\"\n",
    "\n",
    "FEATURE_LIST = [\n",
    "    \"origScore\", \"titleSimTFIDF\", \"titleSimBM25\", \"descSimTFIDF\", \"descSimBM25\",\n",
    "    \"docRecency\", \"isGoHands\", \"isAniplex\", \"isThriller\", \"isForeign\",\n",
    "    \"isDrama\", \"isWar\", \"isAction\", \"isComedy\", \"isMusic\", \n",
    "    \"isRomance\", \"isAdventure\", \"isFamily\", \"isFantasy\", \"isCrime\",\n",
    "    \"isHorror\", \"isHistory\", \"isMystery\", \"isAnimation\", \"isDocumentary\",\n",
    "    \"isWestern\"\n",
    "]\n",
    "QUERY_LIST = [\n",
    "    \"murder\", \"musical\", \"biography\", \"police\", \"world war ii\",\n",
    "    \"comedy\", \"superhero\", \"nazis\", \"romance\", \"martial arts\",\n",
    "    \"extramarital\", \"spy\", \"vampire\", \"magic\", \"wedding\",\n",
    "    \"sport\", \"prison\", \"teacher\", \"alien\", \"dystopia\"\n",
    "]\n",
    "TOP_N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plugin Setup\n",
    "\n",
    "The LTR functionality is bundled into Apache Solr since 6.x, but it needs to be enabled.\n",
    "\n",
    "### Create new core\n",
    "    \n",
    "We then create a new core to hold our index.\n",
    "\n",
    "    bin/solr create -c tmdbindex \n",
    "    \n",
    "In case you need to start over, the command to drop the core is as follows.\n",
    "\n",
    "    bin/solr delete -c tmdbindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Core for LTR\n",
    "\n",
    "We have to add the following snippet into the solrconfig.xml file.\n",
    "\n",
    "    cd <solr_home>\n",
    "    bin/solr stop\n",
    "    vi server/solr/tmdbindex/conf/solrconfig.xml\n",
    "    \n",
    "Add following snippet __before__ the `</config>` tag on the last line of solrconfig.xml.\n",
    "\n",
    "    <lib dir=\"${solr.install.dir:../../../..}/contrib/ltr/lib/\" regex=\".*\\.jar\" />\n",
    "    <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-ltr-\\d.*\\.jar\" />\n",
    "\n",
    "    <queryParser name=\"ltr\" class=\"org.apache.solr.ltr.search.LTRQParserPlugin\"/>\n",
    "\n",
    "    <cache name=\"QUERY_DOC_FV\"\n",
    "           class=\"solr.search.LRUCache\"\n",
    "           size=\"4096\"\n",
    "           initialSize=\"2048\"\n",
    "           autowarmCount=\"4096\"\n",
    "           regenerator=\"solr.search.NoOpRegenerator\" />\n",
    "\n",
    "    <transformer name=\"features\" class=\"org.apache.solr.ltr.response.transform.LTRFeatureLoggerTransformerFactory\">\n",
    "      <str name=\"fvCacheName\">QUERY_DOC_FV</str>\n",
    "    </transformer>\n",
    "    \n",
    "Restart Solr with LTR enabled.\n",
    "\n",
    "    bin/solr start -Dsolr.ltr.enabled=true\n",
    "    \n",
    "We are now ready to define LTR features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "### Add \"TF-IDF\" fields to schema\n",
    "\n",
    "Since Solr 6.x the default similarity has changed to be BM25, and the old TF-IDF based similarity can be accessed using ClassicSimilarity. So we will declare a new field type `text_tfidf` that uses the TF-IDF based similarity. Any field declared (via the dynamic field naming convention) with the suffix `_t` will automatically be of type `text_general` which uses BM25 similarity. \n",
    "\n",
    "In addition, we declare a copy-field that will copy the title `title_t` and body field `description_t` (BM25 similarity) fields to their corresponding counterparts `title_tfidf` and `description_tfidf` automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":80}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Content-type\": \"application/json\"}\n",
    "data = {\n",
    "  \"add-field-type\" : {\n",
    "    \"name\":\"text_tfidf\",\n",
    "    \"class\":\"solr.TextField\",\n",
    "    \"positionIncrementGap\":\"100\",\n",
    "    \"indexAnalyzer\":{\n",
    "       \"tokenizer\":{\n",
    "          \"class\":\"solr.StandardTokenizerFactory\"},\n",
    "       \"filter\":{\n",
    "          \"class\":\"solr.StopFilterFactory\",\n",
    "          \"ignoreCase\":\"true\",\n",
    "          \"words\":\"stopwords.txt\"},\n",
    "       \"filter\":{\n",
    "          \"class\":\"solr.LowerCaseFilterFactory\"}\n",
    "    },\n",
    "    \"queryAnalyzer\":{\n",
    "       \"tokenizer\":{\n",
    "          \"class\":\"solr.StandardTokenizerFactory\"},\n",
    "       \"filter\":{\n",
    "          \"class\":\"solr.StopFilterFactory\",\n",
    "          \"ignoreCase\":\"true\",\n",
    "          \"words\":\"stopwords.txt\"},\n",
    "       \"filter\":{\n",
    "          \"class\":\"solr.SynonymGraphFilterFactory\",\n",
    "          \"ignoreCase\":\"true\",\n",
    "          \"synonyms\":\"synonyms.txt\"},\n",
    "       \"filter\":{\n",
    "          \"class\":\"solr.LowerCaseFilterFactory\"}\n",
    "    },\n",
    "    \"similarity\":{\n",
    "          \"class\":\"solr.ClassicSimilarityFactory\"\n",
    "    }\n",
    "  },\n",
    "  \"add-dynamic-field\": {\n",
    "    \"name\": \"*_tfidf\",\n",
    "    \"type\": \"text_tfidf\",\n",
    "    \"indexed\": \"true\",\n",
    "    \"stored\": \"true\"\n",
    "  },\n",
    "  \"add-copy-field\": {\n",
    "    \"source\": \"title_t\",\n",
    "    \"dest\": \"title_tfidf\"\n",
    "  },\n",
    "  \"add-copy-field\": {\n",
    "    \"source\": \"description_t\",\n",
    "    \"dest\": \"description_tfidf\"\n",
    "  }\n",
    "}\n",
    "resp = requests.post(SOLR_URL + \"/schema\", headers=headers, data=json.dumps(data))\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Records into Solr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['electricity', 'scientific experiment', 'nikola tesla']\n"
     ]
    }
   ],
   "source": [
    "def get_keywords(conn, movie_id):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select keywords from keywords where mid = ?\", [movie_id])\n",
    "    rows = cur.fetchall()\n",
    "    keywords = []\n",
    "    if len(rows) > 0:\n",
    "        for row in rows:\n",
    "            keywords = row[0].split(\"|\")\n",
    "            break\n",
    "    cur.close()\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def filter_genres(conn, genres):\n",
    "    filtered_genres = []\n",
    "    cur = conn.cursor()\n",
    "    for genre in genres:\n",
    "        cur.execute(\"select gname from genres where gname = ?\", [genre])\n",
    "        rows = cur.fetchall()\n",
    "        if len(rows) == 0:\n",
    "            continue\n",
    "        filtered_genres.append(genre)\n",
    "    cur.close()\n",
    "    return filtered_genres\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(LOOKUPS_DB)\n",
    "print(get_keywords(conn, 460870))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records ingested into Solr\n",
      "1000 records ingested into Solr\n",
      "2000 records ingested into Solr\n",
      "3000 records ingested into Solr\n",
      "4000 records ingested into Solr\n",
      "5000 records ingested into Solr\n",
      "6000 records ingested into Solr\n",
      "7000 records ingested into Solr\n",
      "8000 records ingested into Solr\n",
      "9000 records ingested into Solr\n",
      "10000 records ingested into Solr\n",
      "11000 records ingested into Solr\n",
      "12000 records ingested into Solr\n",
      "13000 records ingested into Solr\n",
      "14000 records ingested into Solr\n",
      "15000 records ingested into Solr\n",
      "16000 records ingested into Solr\n",
      "17000 records ingested into Solr\n",
      "18000 records ingested into Solr\n",
      "19000 records ingested into Solr\n",
      "20000 records ingested into Solr\n",
      "21000 records ingested into Solr\n",
      "22000 records ingested into Solr\n",
      "23000 records ingested into Solr\n",
      "24000 records ingested into Solr\n",
      "25000 records ingested into Solr\n",
      "26000 records ingested into Solr\n",
      "27000 records ingested into Solr\n",
      "28000 records ingested into Solr\n",
      "29000 records ingested into Solr\n",
      "30000 records ingested into Solr\n",
      "31000 records ingested into Solr\n",
      "32000 records ingested into Solr\n",
      "33000 records ingested into Solr\n",
      "34000 records ingested into Solr\n",
      "35000 records ingested into Solr\n",
      "36000 records ingested into Solr\n",
      "37000 records ingested into Solr\n",
      "38000 records ingested into Solr\n",
      "39000 records ingested into Solr\n",
      "40000 records ingested into Solr\n",
      "41000 records ingested into Solr\n",
      "42000 records ingested into Solr\n",
      "43000 records ingested into Solr\n",
      "44000 records ingested into Solr\n",
      "45000 records ingested into Solr\n",
      "45466 records ingested into Solr, COMPLETE\n"
     ]
    }
   ],
   "source": [
    "def get_float(orig_value, default_value):\n",
    "    if orig_value is None:\n",
    "        return default_value\n",
    "    elif len(orig_value.strip()) == 0:\n",
    "        return default_value\n",
    "    else:\n",
    "        return float(orig_value)\n",
    "    \n",
    "def parse_genres(genre_json):\n",
    "    if len(genre_json.strip()) == 0:\n",
    "        return []\n",
    "    names = []\n",
    "    idname_pairs = json.loads(genre_json.replace(\"'\", \"\\\"\"))\n",
    "    for idname_pair in idname_pairs:\n",
    "        names.append(idname_pair[\"name\"])\n",
    "    return names\n",
    "\n",
    "\n",
    "def add_record_to_solr(solr_url, doc_id, title, description, popularity, \n",
    "                       release_date, revenue, runtime, rating, keywords, genres,\n",
    "                       should_commit=False):\n",
    "    headers = {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "    if doc_id is None:\n",
    "        # only do a commit\n",
    "        requests.post(solr_url + \"update\", params={\"commit\": \"true\"}, headers=headers)\n",
    "    else:\n",
    "        req_body = json.dumps({\n",
    "            \"add\": {\n",
    "                \"doc\": {\n",
    "                    \"id\": doc_id,\n",
    "                    \"title_t\": title,\n",
    "                    \"description_t\": description,\n",
    "                    \"popularity_f\": popularity,\n",
    "                    \"released_dt\": release_date,\n",
    "                    \"revenue_f\": revenue,\n",
    "                    \"runtime_f\": runtime,\n",
    "                    \"rating_f\": rating,\n",
    "                    \"keywords_ss\": keywords,\n",
    "                    \"genres_ss\": genres\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "        params = { \"commit\": \"true\" if should_commit else \"false\" }\n",
    "        requests.post(solr_url + \"/update\", data=req_body, params=params, headers=headers)\n",
    "        \n",
    "\n",
    "i = 0\n",
    "should_commit = False\n",
    "with open(MOVIES_DATA, \"r\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if i % 1000 == 0:\n",
    "            print(\"{:d} records ingested into Solr\".format(i))\n",
    "            should_commit = True\n",
    "        if row[\"original_language\"] != \"en\":\n",
    "            # only stick to english\n",
    "            i += 1\n",
    "            continue\n",
    "        doc_id = int(row[\"id\"])\n",
    "        title = row[\"original_title\"]\n",
    "        description = row[\"overview\"]\n",
    "        popularity = get_float(row[\"popularity\"], 0.0)\n",
    "        release_date = row[\"release_date\"]\n",
    "        revenue = get_float(row[\"revenue\"], 0.0)\n",
    "        runtime = get_float(row[\"runtime\"], 0.0)\n",
    "        rating = get_float(row[\"vote_average\"], 0.0)\n",
    "        # look up keywords\n",
    "        keywords = get_keywords(conn, doc_id)\n",
    "        # parse out genres\n",
    "        genres = filter_genres(conn, parse_genres(row[\"genres\"]))\n",
    "        # add record to solr\n",
    "        add_record_to_solr(SOLR_URL, doc_id, title, description, popularity, \n",
    "                           release_date, revenue, runtime, rating, keywords, genres,\n",
    "                           should_commit=should_commit)\n",
    "        should_commit = False\n",
    "        i += 1\n",
    "\n",
    "add_record_to_solr(SOLR_URL, None, None, None, None, None, None, None, None, None, None, True)\n",
    "print(\"{:d} records ingested into Solr, COMPLETE\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LTR Features\n",
    "\n",
    "LTR features are defined as function queries. See [the Solr LTR Documentation](https://lucene.apache.org/solr/guide/7_4/learning-to-rank.html) for examples and details of the feature classes supported (OriginalScoreFeature, SolrFeature and ValueFeature).\n",
    "\n",
    "As before, we can use Solr's JSON API to define and upload the LTR feature set to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":143}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Content-type\": \"application/json\"}\n",
    "data = [\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"origScore\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.OriginalScoreFeature\",\n",
    "    \"params\": {}\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"titleSimTFIDF\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"q\": \"{!dismax qf=title_tfidf}${query}\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"titleSimBM25\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"q\": \"{!dismax qf=title_t}${query}\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"descSimTFIDF\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"q\": \"{!dismax qf=description_tfidf}${query}\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"descSimBM25\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"q\": \"{!dismax qf=description_t}${query}\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"docRecency\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"q\": \"{!func}recip(ms(NOW, released_dt), 3.16e-11, 1, 1)\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isGoHands\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}GoHands\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isAniplex\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Aniplex\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isThriller\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Thriller\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isForeign\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Foreign\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isDrama\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Drama\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isWar\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}War\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isAction\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Action\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isComedy\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Comedy\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isMusic\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Music\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isRomance\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Romance\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isAdventure\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Adventure\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isFamily\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Family\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isFantasy\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Fantasy\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isCrime\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Crime\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isHorror\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Horror\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isHistory\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}History\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isMystery\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Mystery\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isAnimation\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Animation\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isDocumentary\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Documentary\"]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"isWestern\",\n",
    "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "    \"params\": {\n",
    "      \"fq\": [\"{!terms f=genres_ss}Western\"]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "resp = requests.put(SOLR_URL + \"/schema/feature-store\", headers=headers, data=json.dumps(data))\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LTR features\n",
    "\n",
    "### Create Dummy LinearModel\n",
    "\n",
    "The [Solr LTR docs](https://lucene.apache.org/solr/guide/7_4/learning-to-rank.html) imply that we can just call the following URL to get the values of the computed features for a given query `q`:\n",
    "\n",
    "    http://localhost:8983/solr/tmdbindex/query?q=%22martial%20arts%22&fl=id,score,[features]\n",
    "\n",
    "But since we have SolrFeature type parameters, these need to be computed in the context of an actual query, so we need to do a little more work. Namely, we construct a dummy LinearModel `solr_feature_ltr_model.json` where the __only feature that is turned on is the original score feature__, then push it into Solr using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":10}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Content-type\": \"application/json\"}\n",
    "data = {\n",
    "  \"store\" : \"myFeatureStore\",\n",
    "  \"name\" : \"myLinearModel\",\n",
    "  \"class\" : \"org.apache.solr.ltr.model.LinearModel\",\n",
    "  \"features\" : [\n",
    "    { \"name\": \"origScore\" },\n",
    "    { \"name\": \"titleSimTFIDF\" },\n",
    "    { \"name\": \"titleSimBM25\" },\n",
    "    { \"name\": \"descSimTFIDF\" },\n",
    "    { \"name\": \"descSimBM25\" },\n",
    "    { \"name\": \"docRecency\" },\n",
    "    { \"name\": \"isGoHands\" },\n",
    "    { \"name\": \"isAniplex\" },\n",
    "    { \"name\": \"isThriller\" },\n",
    "    { \"name\": \"isForeign\" },\n",
    "    { \"name\": \"isDrama\" },\n",
    "    { \"name\": \"isWar\" },\n",
    "    { \"name\": \"isAction\" },\n",
    "    { \"name\": \"isComedy\" },\n",
    "    { \"name\": \"isMusic\" },\n",
    "    { \"name\": \"isRomance\" },\n",
    "    { \"name\": \"isAdventure\" },\n",
    "    { \"name\": \"isFamily\" },\n",
    "    { \"name\": \"isFantasy\" },\n",
    "    { \"name\": \"isCrime\" },\n",
    "    { \"name\": \"isHorror\" },\n",
    "    { \"name\": \"isHistory\" },\n",
    "    { \"name\": \"isMystery\" },\n",
    "    { \"name\": \"isAnimation\" },\n",
    "    { \"name\": \"isDocumentary\" },\n",
    "    { \"name\": \"isWestern\" }\n",
    "  ],\n",
    "  \"params\" : {\n",
    "    \"weights\" : {\n",
    "      \"origScore\": 1.0,\n",
    "      \"titleSimTFIDF\": 0.0,\n",
    "      \"titleSimBM25\": 0.0,\n",
    "      \"descSimTFIDF\": 0.0,\n",
    "      \"descSimBM25\": 0.0,\n",
    "      \"docRecency\": 0.0,\n",
    "      \"isGoHands\": 0.0,\n",
    "      \"isAniplex\": 0.0,\n",
    "      \"isThriller\": 0.0,\n",
    "      \"isForeign\": 0.0,\n",
    "      \"isDrama\": 0.0,\n",
    "      \"isWar\": 0.0,\n",
    "      \"isAction\": 0.0,\n",
    "      \"isComedy\": 0.0,\n",
    "      \"isMusic\": 0.0,\n",
    "      \"isRomance\": 0.0,\n",
    "      \"isAdventure\": 0.0,\n",
    "      \"isFamily\": 0.0,\n",
    "      \"isFantasy\": 0.0,\n",
    "      \"isCrime\": 0.0,\n",
    "      \"isHorror\": 0.0,\n",
    "      \"isHistory\": 0.0,\n",
    "      \"isMystery\": 0.0,\n",
    "      \"isAnimation\": 0.0,\n",
    "      \"isDocumentary\": 0.0,\n",
    "      \"isWestern\": 0.0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "resp = requests.put(SOLR_URL + \"/schema/model-store\", headers=headers, data=json.dumps(data))\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features to LETOR format\n",
    "\n",
    "To run a query and get back feature values, use following URL:\n",
    "\n",
    "    http://localhost:8983/solr/tmdbindex/query?q=%22martial%20arts%22&df=description_t&rq={!ltr%20model=myLinearModel%20efi.query=%27martial%20arts%27}&fl=id,score,[features]\n",
    "    \n",
    "We will now extract the features for a given set of queries and write it out in [LETOR format](https://sourceforge.net/p/lemur/wiki/RankLib%20File%20Format/). The dataset will be used to train a RankLib LambdaMart model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating2label(rating):\n",
    "    \"\"\" convert 0-10 continuous rating to 1-5 categorical labels \"\"\"\n",
    "    return int(rating // 2) + 1\n",
    "\n",
    "assert(rating2label(6.4) == 4)\n",
    "assert(rating2label(9.8) == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name2id = {name: idx + 1 for idx, name in enumerate(FEATURE_LIST)}\n",
    "\n",
    "assert(feature_name2id[\"isRomance\"] == 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 qid:1 1:9.458602 2:0.0 3:0.0 4:2.3550842 5:9.458602 6:0.07054524 7:0 8:0 9:0 10:0 11:0 12:0 13:0 14:0 15:0 16:0 17:0 18:0 19:0 20:0 21:0 22:0 23:0 24:0 25:1 26:0 # docid:192143 query:biography\n"
     ]
    }
   ],
   "source": [
    "def format_letor(doc_id, rating, feat_str, qid, query):\n",
    "    label = rating2label(rating)\n",
    "    feat_pairs = []\n",
    "    for feat_nv in feat_str.split(\",\"):\n",
    "        feat_name, feat_val = feat_nv.split(\"=\")\n",
    "        feat_id = str(feature_name2id[feat_name])\n",
    "        feat_val = float(feat_val)\n",
    "        if feat_name.startswith(\"is\"):\n",
    "            feat_val = int(feat_val)\n",
    "        feat_val = str(feat_val)\n",
    "        feat_pairs.append(\":\".join([feat_id, feat_val]))\n",
    "    return \"{:d} qid:{:d} {:s} # docid:{:d} query:{:s}\".format(\n",
    "        label, qid, \" \".join(feat_pairs), doc_id, query)\n",
    "\n",
    "print(format_letor(192143, 4.5, \"origScore=9.458602,titleSimTFIDF=0.0,titleSimBM25=0.0,descSimTFIDF=2.3550842,descSimBM25=9.458602,docRecency=0.07054524,isGoHands=0.0,isAniplex=0.0,isThriller=0.0,isForeign=0.0,isDrama=0.0,isWar=0.0,isAction=0.0,isComedy=0.0,isMusic=0.0,isRomance=0.0,isAdventure=0.0,isFamily=0.0,isFantasy=0.0,isCrime=0.0,isHorror=0.0,isHistory=0.0,isMystery=0.0,isAnimation=0.0,isDocumentary=1.0,isWestern=0.0\", 1, \"biography\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating feature for alien (train)\n",
      "generating feature for romance (train)\n",
      "generating feature for police (train)\n",
      "generating feature for world war ii (train)\n",
      "generating feature for prison (train)\n",
      "generating feature for biography (train)\n",
      "generating feature for nazis (train)\n",
      "generating feature for magic (train)\n",
      "generating feature for spy (train)\n",
      "generating feature for martial arts (train)\n",
      "generating feature for vampire (train)\n",
      "generating feature for superhero (train)\n",
      "generating feature for musical (val)\n",
      "generating feature for dystopia (val)\n",
      "generating feature for teacher (val)\n",
      "generating feature for murder (test)\n",
      "generating feature for sport (test)\n",
      "generating feature for extramarital (test)\n",
      "generating feature for comedy (test)\n",
      "generating feature for wedding (test)\n",
      "number of queries, train 12, test 5, validation 3\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(QUERY_LIST)\n",
    "train_queries = QUERY_LIST[0:12]\n",
    "val_queries = QUERY_LIST[12:15]\n",
    "test_queries = QUERY_LIST[15:]\n",
    "feat_suffixes = [\"train\", \"val\", \"test\"]\n",
    "qid = 1\n",
    "for qt_idx, queries in enumerate([train_queries, val_queries, test_queries]):\n",
    "    fletor = open(FEATURE_FILE_TEMPLATE.format(feat_suffixes[qt_idx]), \"w\")\n",
    "    for query in queries:\n",
    "        print(\"generating feature for {:s} ({:s})\".format(query, feat_suffixes[qt_idx]))\n",
    "        if len(query.split()) > 1:\n",
    "            query = \"\\\"\" + query + \"\\\"\"\n",
    "        payload = {\n",
    "            \"q\": query,\n",
    "            \"defType\": \"edismax\",\n",
    "            \"qf\": \"title_t description_t\",\n",
    "            \"pf\": \"title_t description_t\",\n",
    "            \"mm\": 2,\n",
    "            \"rq\": \"{!ltr model=myLinearModel efi.query=\" + query + \"}\",\n",
    "            \"fl\": \"id,rating_f,[features]\",            \n",
    "            \"rows\": 100\n",
    "        }\n",
    "        params = urllib.parse.urlencode(payload, quote_via=urllib.parse.quote_plus)\n",
    "        search_url = SOLR_URL + \"/select?\" + params\n",
    "        resp = requests.get(search_url)\n",
    "        resp_json = json.loads(resp.text)\n",
    "        for doc in resp_json[\"response\"][\"docs\"]:\n",
    "            doc_id = int(doc[\"id\"])\n",
    "            rating = doc[\"rating_f\"]\n",
    "            feat_str = doc[\"[features]\"]\n",
    "            fletor.write(\"{:s}\\n\".format(format_letor(doc_id, rating, feat_str, qid, query)))\n",
    "        qid += 1\n",
    "    fletor.close()\n",
    "print(\"number of queries, train {:d}, test {:d}, validation {:d}\".format(\n",
    "    len(train_queries), len(test_queries), len(val_queries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LTR model using RankLib\n",
    "\n",
    "We train a LambdaMart model using [RankLib](https://sourceforge.net/p/lemur/wiki/RankLib%20How%20to%20use/) using its command line interface as shown below.\n",
    "\n",
    "    cd <scripts_dir>\n",
    "    java -jar RankLib-2.10.jar \\\n",
    "        -train ../data/solr_features_train.txt \\\n",
    "        -test ../data/solr_features_test.txt \\\n",
    "        -validate ../data/solr_features_val.txt \\\n",
    "        -ranker 6 \\\n",
    "        -metric2t NDCG@10 \\\n",
    "        -metric2T NDCG@10 \\\n",
    "        -save ../models/solr_lambdamart_model.txt\n",
    "\n",
    "Console output is shown below:\n",
    "\n",
    "    Discard orig. features\n",
    "    Training data:\t../data/solr_features_train.txt\n",
    "    Test data:\t../data/solr_features_test.txt\n",
    "    Validation data:\t../data/solr_features_val.txt\n",
    "    Feature vector representation: Dense.\n",
    "    Ranking method:\tLambdaMART\n",
    "    Feature description file:\tUnspecified. All features will be used.\n",
    "    Train metric:\tNDCG@10\n",
    "    Test metric:\tNDCG@10\n",
    "    Feature normalization: No\n",
    "    Model file: ../models/solr_lambdamart_model.txt\n",
    "    \n",
    "    [+] LambdaMART's Parameters:\n",
    "    No. of trees: 1000\n",
    "    No. of leaves: 10\n",
    "    No. of threshold candidates: 256\n",
    "    Min leaf support: 1\n",
    "    Learning rate: 0.1\n",
    "    Stop early: 100 rounds without performance gain on validation data\n",
    "    \n",
    "    Reading feature file [../data/solr_features_train.txt]... [Done.]            \n",
    "    (12 ranked lists, 1039 entries read)\n",
    "    Reading feature file [../data/solr_features_val.txt]... [Done.]            \n",
    "    (3 ranked lists, 257 entries read)\n",
    "    Reading feature file [../data/solr_features_test.txt]... [Done.]            \n",
    "    (5 ranked lists, 402 entries read)\n",
    "    Initializing... [Done]\n",
    "    ---------------------------------\n",
    "    Training starts...\n",
    "    ---------------------------------\n",
    "    #iter   | NDCG@10-T | NDCG@10-V | \n",
    "    ---------------------------------\n",
    "    1       | 0.5858    | 0.4278    | \n",
    "    2       | 0.6125    | 0.4547    | \n",
    "    3       | 0.6073    | 0.4931    | \n",
    "    4       | 0.617     | 0.4778    | \n",
    "    5       | 0.6361    | 0.4797    | \n",
    "    6       | 0.6377    | 0.4723    | \n",
    "    7       | 0.6382    | 0.4706    | \n",
    "    8       | 0.6374    | 0.4741    | \n",
    "    9       | 0.6435    | 0.4606    | \n",
    "    10      | 0.6417    | 0.4606    | \n",
    "    11      | 0.6434    | 0.4773    | \n",
    "    12      | 0.6424    | 0.4851    | \n",
    "    13      | 0.6484    | 0.4847    | \n",
    "    14      | 0.659     | 0.4988    | \n",
    "    15      | 0.679     | 0.4988    | \n",
    "    16      | 0.6794    | 0.4988    | \n",
    "    17      | 0.6861    | 0.5005    | \n",
    "    18      | 0.6867    | 0.4864    | \n",
    "    19      | 0.6934    | 0.5305    | \n",
    "    20      | 0.6956    | 0.5247    | \n",
    "    21      | 0.7165    | 0.5234    | \n",
    "    22      | 0.7154    | 0.5177    | \n",
    "    23      | 0.7108    | 0.5004    | \n",
    "    24      | 0.7111    | 0.4932    | \n",
    "    25      | 0.7219    | 0.5037    | \n",
    "    26      | 0.7301    | 0.5051    | \n",
    "    27      | 0.7256    | 0.493     | \n",
    "    28      | 0.7189    | 0.493     | \n",
    "    29      | 0.7339    | 0.4933    | \n",
    "    30      | 0.7323    | 0.4878    | \n",
    "    31      | 0.7476    | 0.483     | \n",
    "    32      | 0.7447    | 0.4982    | \n",
    "    33      | 0.7421    | 0.4909    | \n",
    "    34      | 0.7407    | 0.4836    | \n",
    "    35      | 0.756     | 0.4912    | \n",
    "    36      | 0.7545    | 0.4912    | \n",
    "    37      | 0.757     | 0.4924    | \n",
    "    38      | 0.7561    | 0.4943    | \n",
    "    39      | 0.7598    | 0.496     | \n",
    "    40      | 0.764     | 0.5018    | \n",
    "    41      | 0.7626    | 0.4889    | \n",
    "    42      | 0.7678    | 0.5095    | \n",
    "    43      | 0.7677    | 0.5089    | \n",
    "    44      | 0.7658    | 0.5023    | \n",
    "    45      | 0.7625    | 0.5026    | \n",
    "    46      | 0.7632    | 0.5015    | \n",
    "    47      | 0.7643    | 0.5019    | \n",
    "    48      | 0.7681    | 0.4931    | \n",
    "    49      | 0.7681    | 0.4974    | \n",
    "    50      | 0.7708    | 0.4974    | \n",
    "    51      | 0.7733    | 0.4944    | \n",
    "    52      | 0.7791    | 0.4968    | \n",
    "    53      | 0.7834    | 0.4981    | \n",
    "    54      | 0.7813    | 0.4985    | \n",
    "    55      | 0.7765    | 0.5333    | \n",
    "    56      | 0.777     | 0.5329    | \n",
    "    57      | 0.7742    | 0.5321    | \n",
    "    58      | 0.7785    | 0.53      | \n",
    "    59      | 0.7762    | 0.5226    | \n",
    "    60      | 0.775     | 0.5336    | \n",
    "    61      | 0.7844    | 0.5336    | \n",
    "    62      | 0.7843    | 0.5353    | \n",
    "    63      | 0.796     | 0.5318    | \n",
    "    64      | 0.792     | 0.5319    | \n",
    "    65      | 0.7967    | 0.5302    | \n",
    "    66      | 0.7996    | 0.5311    | \n",
    "    67      | 0.7998    | 0.5311    | \n",
    "    68      | 0.7978    | 0.5302    | \n",
    "    69      | 0.7992    | 0.5299    | \n",
    "    70      | 0.8023    | 0.5299    | \n",
    "    71      | 0.7998    | 0.4988    | \n",
    "    72      | 0.7996    | 0.4992    | \n",
    "    73      | 0.801     | 0.4971    | \n",
    "    74      | 0.8111    | 0.5265    | \n",
    "    75      | 0.8108    | 0.5229    | \n",
    "    76      | 0.8172    | 0.4927    | \n",
    "    77      | 0.8158    | 0.4852    | \n",
    "    78      | 0.8145    | 0.494     | \n",
    "    79      | 0.8202    | 0.4892    | \n",
    "    80      | 0.8215    | 0.494     | \n",
    "    81      | 0.8197    | 0.494     | \n",
    "    82      | 0.8177    | 0.494     | \n",
    "    83      | 0.8171    | 0.5046    | \n",
    "    84      | 0.819     | 0.5051    | \n",
    "    85      | 0.8236    | 0.5056    | \n",
    "    86      | 0.8181    | 0.506     | \n",
    "    87      | 0.8187    | 0.5064    | \n",
    "    88      | 0.8222    | 0.5055    | \n",
    "    89      | 0.8185    | 0.5055    | \n",
    "    90      | 0.8229    | 0.5055    | \n",
    "    91      | 0.8204    | 0.4988    | \n",
    "    92      | 0.829     | 0.4984    | \n",
    "    93      | 0.8296    | 0.4984    | \n",
    "    94      | 0.8396    | 0.5079    | \n",
    "    95      | 0.8394    | 0.5082    | \n",
    "    96      | 0.8431    | 0.5088    | \n",
    "    97      | 0.8467    | 0.5084    | \n",
    "    98      | 0.8467    | 0.5088    | \n",
    "    99      | 0.8504    | 0.52      | \n",
    "    100     | 0.8496    | 0.5227    | \n",
    "    101     | 0.8536    | 0.5234    | \n",
    "    102     | 0.8516    | 0.5239    | \n",
    "    103     | 0.8482    | 0.5415    | \n",
    "    104     | 0.8558    | 0.5394    | \n",
    "    105     | 0.8559    | 0.5393    | \n",
    "    106     | 0.853     | 0.5396    | \n",
    "    107     | 0.8586    | 0.5389    | \n",
    "    108     | 0.8529    | 0.5397    | \n",
    "    109     | 0.8549    | 0.5381    | \n",
    "    110     | 0.8587    | 0.5402    | \n",
    "    111     | 0.8587    | 0.5402    | \n",
    "    112     | 0.8546    | 0.538     | \n",
    "    113     | 0.8566    | 0.5388    | \n",
    "    114     | 0.8572    | 0.5392    | \n",
    "    115     | 0.8569    | 0.5387    | \n",
    "    116     | 0.8605    | 0.5402    | \n",
    "    117     | 0.8592    | 0.5398    | \n",
    "    118     | 0.8601    | 0.5229    | \n",
    "    119     | 0.8634    | 0.5127    | \n",
    "    120     | 0.858     | 0.5135    | \n",
    "    121     | 0.8665    | 0.5131    | \n",
    "    122     | 0.8703    | 0.5117    | \n",
    "    123     | 0.8694    | 0.5064    | \n",
    "    124     | 0.8677    | 0.5069    | \n",
    "    125     | 0.8725    | 0.5069    | \n",
    "    126     | 0.8717    | 0.5315    | \n",
    "    127     | 0.8664    | 0.5244    | \n",
    "    128     | 0.8714    | 0.5256    | \n",
    "    129     | 0.8781    | 0.5256    | \n",
    "    130     | 0.875     | 0.5363    | \n",
    "    131     | 0.8827    | 0.5137    | \n",
    "    132     | 0.8825    | 0.508     | \n",
    "    133     | 0.8843    | 0.5073    | \n",
    "    134     | 0.8865    | 0.5037    | \n",
    "    135     | 0.8856    | 0.5034    | \n",
    "    136     | 0.8826    | 0.5034    | \n",
    "    137     | 0.8862    | 0.504     | \n",
    "    138     | 0.8905    | 0.5146    | \n",
    "    139     | 0.8954    | 0.5142    | \n",
    "    140     | 0.8943    | 0.5024    | \n",
    "    141     | 0.8947    | 0.5026    | \n",
    "    142     | 0.8957    | 0.4931    | \n",
    "    143     | 0.8967    | 0.5007    | \n",
    "    144     | 0.8987    | 0.5012    | \n",
    "    145     | 0.9006    | 0.5122    | \n",
    "    146     | 0.8994    | 0.5049    | \n",
    "    147     | 0.8992    | 0.5049    | \n",
    "    148     | 0.9045    | 0.5302    | \n",
    "    149     | 0.9047    | 0.5122    | \n",
    "    150     | 0.9052    | 0.5111    | \n",
    "    151     | 0.9088    | 0.5107    | \n",
    "    152     | 0.9077    | 0.5082    | \n",
    "    153     | 0.9071    | 0.5199    | \n",
    "    154     | 0.904     | 0.5239    | \n",
    "    155     | 0.9052    | 0.5238    | \n",
    "    156     | 0.9043    | 0.5183    | \n",
    "    157     | 0.9041    | 0.5233    | \n",
    "    158     | 0.9046    | 0.5252    | \n",
    "    159     | 0.9029    | 0.5316    | \n",
    "    160     | 0.9122    | 0.5341    | \n",
    "    161     | 0.9181    | 0.5341    | \n",
    "    162     | 0.9144    | 0.5341    | \n",
    "    163     | 0.9127    | 0.5327    | \n",
    "    164     | 0.9154    | 0.5327    | \n",
    "    165     | 0.9146    | 0.5268    | \n",
    "    166     | 0.9186    | 0.5268    | \n",
    "    167     | 0.9185    | 0.5268    | \n",
    "    168     | 0.9176    | 0.5268    | \n",
    "    169     | 0.9167    | 0.5268    | \n",
    "    170     | 0.917     | 0.5268    | \n",
    "    171     | 0.9194    | 0.5272    | \n",
    "    172     | 0.9218    | 0.5201    | \n",
    "    173     | 0.9168    | 0.5206    | \n",
    "    174     | 0.9213    | 0.524     | \n",
    "    175     | 0.9236    | 0.5234    | \n",
    "    176     | 0.9229    | 0.5234    | \n",
    "    177     | 0.9221    | 0.5258    | \n",
    "    178     | 0.9228    | 0.5208    | \n",
    "    179     | 0.9246    | 0.5179    | \n",
    "    180     | 0.9218    | 0.5255    | \n",
    "    181     | 0.9264    | 0.5289    | \n",
    "    182     | 0.923     | 0.5278    | \n",
    "    183     | 0.9202    | 0.5231    | \n",
    "    184     | 0.9214    | 0.5309    | \n",
    "    185     | 0.9249    | 0.5303    | \n",
    "    186     | 0.9249    | 0.5295    | \n",
    "    187     | 0.9249    | 0.5295    | \n",
    "    188     | 0.9265    | 0.5251    | \n",
    "    189     | 0.9265    | 0.5255    | \n",
    "    190     | 0.9232    | 0.5281    | \n",
    "    191     | 0.9255    | 0.5335    | \n",
    "    192     | 0.9271    | 0.5284    | \n",
    "    193     | 0.9271    | 0.5276    | \n",
    "    194     | 0.9271    | 0.5281    | \n",
    "    195     | 0.9283    | 0.529     | \n",
    "    196     | 0.9286    | 0.5286    | \n",
    "    197     | 0.9295    | 0.529     | \n",
    "    198     | 0.9282    | 0.5286    | \n",
    "    199     | 0.9295    | 0.5286    | \n",
    "    200     | 0.9276    | 0.5286    | \n",
    "    201     | 0.9295    | 0.5294    | \n",
    "    202     | 0.9316    | 0.5294    | \n",
    "    203     | 0.9316    | 0.5284    | \n",
    "    204     | 0.9316    | 0.5284    | \n",
    "    ---------------------------------\n",
    "    Finished sucessfully.\n",
    "    NDCG@10 on training data: 0.8482\n",
    "    NDCG@10 on validation data: 0.5415\n",
    "    ---------------------------------\n",
    "    NDCG@10 on test data: 0.5944\n",
    "    \n",
    "    Model saved to: ../models/solr_lambdamart_model.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload trained model\n",
    "\n",
    "Resulting LambdaMART model looks like [this](https://github.com/sujitpal/ltr-examples/blob/master/models/solr_lambdamart_model.txt).\n",
    "\n",
    "\n",
    "### Convert model file to JSON\n",
    "\n",
    "Note that this is in XML format. It needs to be converted to JSON format before being uploaded to Solr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraw = open(RANKLIB_LM_MODEL, \"r\")\n",
    "fxml = open(RANKLIB_PROC_LM_MODEL, \"w\")\n",
    "fxml.write(\"<?xml version=\\\"1.0\\\"?>\\n\")\n",
    "for line in fraw:\n",
    "    if line.startswith(\"##\") or len(line.strip()) == 0:\n",
    "        continue\n",
    "    fxml.write(\"{:s}\".format(line))\n",
    "fxml.close()\n",
    "fraw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_split(el_split, feature_id2name, split_type=\"root\"):\n",
    "    if split_type != \"root\":\n",
    "        split_type = el_split.attrib[\"pos\"]\n",
    "    output = el_split.find(\"output\")\n",
    "    if output is not None:\n",
    "        return {\n",
    "            \"value\": output.text.strip()\n",
    "        }\n",
    "    feature = feature_id2name[int(el_split.find(\"feature\").text.strip())]\n",
    "    threshold = el_split.find(\"threshold\").text.strip()\n",
    "    el_csplits = el_split.findall(\"split\")\n",
    "    for el_csplit in el_csplits:\n",
    "        attr_pos = el_csplit.attrib[\"pos\"]\n",
    "        if attr_pos == \"left\":\n",
    "            left = parse_split(el_csplit, feature_id2name, \"left\")\n",
    "        elif attr_pos == \"right\":\n",
    "            right = parse_split(el_csplit, feature_id2name, \"right\")\n",
    "    return {\n",
    "        \"feature\": feature,\n",
    "        \"threshold\": threshold,\n",
    "        \"left\": left,\n",
    "        \"right\": right\n",
    "    }\n",
    "\n",
    "\n",
    "trees = []\n",
    "feature_id2name = {i+1:f for i, f in enumerate(FEATURE_LIST)}\n",
    "xml = ET.parse(RANKLIB_PROC_LM_MODEL)\n",
    "el_ensemble = xml.getroot()\n",
    "for el_tree in el_ensemble:\n",
    "    weight = el_tree.attrib[\"weight\"]\n",
    "    el_split = el_tree.find(\"split\")\n",
    "    tree_dict = {\n",
    "        \"weight\": weight,\n",
    "        \"root\": parse_split(el_split, feature_id2name)\n",
    "    }\n",
    "    trees.append(tree_dict)\n",
    "params_dict = {\"trees\" : trees}\n",
    "    \n",
    "features = [{\"name\": f} for f in FEATURE_LIST]\n",
    "model_dict = {\n",
    "    \"store\": \"myFeatureStore\",\n",
    "    \"name\": \"myLambdaMARTModel\",\n",
    "    \"class\": \"org.apache.solr.ltr.model.MultipleAdditiveTreesModel\",\n",
    "    \"features\": features,\n",
    "    \"params\": params_dict\n",
    "}\n",
    "with open(SOLR_LM_MODEL, \"w\") as fjson:\n",
    "    fjson.write(json.dumps(model_dict, indent=4))\n",
    "os.unlink(RANKLIB_PROC_LM_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":0,\n",
      "    \"QTime\":54}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "with open(SOLR_LM_MODEL, \"r\") as fjson:\n",
    "    for line in fjson:\n",
    "        lines.append(line.strip())\n",
    "data = \" \".join(lines)\n",
    "headers = {\"Content-type\": \"application/json\"}\n",
    "resp = requests.put(SOLR_URL + \"/schema/model-store\", headers=headers, data=data)\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run rerank query\n",
    "\n",
    "We select a random query from our query list and generate results with and without reranking using the trained LTR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★★★☆☆\n",
      "★★★★☆\n"
     ]
    }
   ],
   "source": [
    "def get_rating_string(rating):\n",
    "    rating_string = []\n",
    "    for i in range(rating):\n",
    "        rating_string.append(u\"\\u2605\")\n",
    "    for i in range(5 - rating):\n",
    "        rating_string.append(u\"\\u2606\")\n",
    "    return \"\".join(rating_string)\n",
    "\n",
    "\n",
    "print(get_rating_string(3))\n",
    "print(get_rating_string(rating2label(6.4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = QUERY_LIST[random.randint(0, len(QUERY_LIST))]\n",
    "if len(query.split()) > 1:\n",
    "    query = \"\\\"\" + query + \"\\\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 results without re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 results for biography\n",
      "---\n",
      "★★★☆☆ 192143 9.473 The Last Mogul\n",
      "★★★☆☆ 242631 9.473 So This Is Love\n",
      "★★★☆☆ 046931 9.366 Georg\n",
      "★★★★☆ 043277 9.261 The Great Ziegfeld\n",
      "★★☆☆☆ 043491 9.059 Rhapsody in Blue\n",
      "★★★★☆ 016769 8.961 Coal Miner's Daughter\n",
      "★★☆☆☆ 107973 8.771 The Dolly Sisters\n",
      "★★★☆☆ 101653 8.771 The Magnificent Yankee\n",
      "★★★★☆ 027966 8.767 King of the Underworld\n",
      "★★★☆☆ 042819 8.585 The City of Your Final Destination\n",
      "★☆☆☆☆ 187156 8.502 Jean-Luc Cinema Godard\n",
      "★★★☆☆ 043604 8.415 Viva Villa!\n",
      "★★★★★ 049914 8.415 W.C. Fields and Me\n",
      "★★★☆☆ 022043 8.331 The Profit\n",
      "★★★★☆ 191600 8.248 John Huston: The Man, the Movies, the Maverick\n",
      "★★★☆☆ 085411 8.248 The Three Stooges\n",
      "★★★★★ 102814 8.167 The Beach Boys: An American Band\n",
      "★★★☆☆ 004882 8.167 A Bullet for Pretty Boy\n",
      "★★★★★ 235932 8.167 Le grand Méliès\n",
      "★★★★☆ 004975 8.087 Love Is the Devil: Study for a Portrait of Francis Bacon\n"
     ]
    }
   ],
   "source": [
    "def render_results(docs, query, top_n):\n",
    "    print(\"top {:d} results for {:s}\".format(TOP_N * 2, query))\n",
    "    print(\"---\")\n",
    "    for doc in resp_json[\"response\"][\"docs\"]:\n",
    "        doc_id = int(doc[\"id\"])\n",
    "        stars = get_rating_string(rating2label(float(doc[\"rating_f\"])))\n",
    "        score = float(doc[\"score\"])\n",
    "        title = doc[\"title_t\"]\n",
    "        print(\"{:s} {:06d} {:.3f} {:s}\".format(stars, doc_id, score, title))\n",
    "\n",
    "\n",
    "payload = {\n",
    "    \"q\": query,\n",
    "    \"defType\": \"edismax\",\n",
    "    \"qf\": \"title_t description_t\",\n",
    "    \"pf\": \"title_t description_t\",\n",
    "    \"mm\": 2,\n",
    "    \"fl\": \"id,title_t,rating_f,score\",            \n",
    "    \"rows\": TOP_N * 2\n",
    "}\n",
    "params = urllib.parse.urlencode(payload, quote_via=urllib.parse.quote_plus)\n",
    "search_url = SOLR_URL + \"/select?\" + params\n",
    "resp = requests.get(search_url)\n",
    "resp_json = json.loads(resp.text)\n",
    "docs = resp_json[\"response\"][\"docs\"]\n",
    "render_results(docs, query, TOP_N * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 results with LTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 results for biography\n",
      "---\n",
      "★★☆☆☆ 043491 0.868 Rhapsody in Blue\n",
      "★★★☆☆ 192143 0.517 The Last Mogul\n",
      "★★★☆☆ 046931 -0.056 Georg\n",
      "★★★★☆ 043277 -0.704 The Great Ziegfeld\n",
      "★★★☆☆ 242631 -0.812 So This Is Love\n",
      "★★★☆☆ 101653 -1.163 The Magnificent Yankee\n",
      "★★★☆☆ 042819 -1.306 The City of Your Final Destination\n",
      "★★★★☆ 016769 -1.487 Coal Miner's Daughter\n",
      "★★★★☆ 027966 -1.566 King of the Underworld\n",
      "★★☆☆☆ 107973 -1.835 The Dolly Sisters\n",
      "★☆☆☆☆ 187156 8.502 Jean-Luc Cinema Godard\n",
      "★★★☆☆ 043604 8.415 Viva Villa!\n",
      "★★★★★ 049914 8.415 W.C. Fields and Me\n",
      "★★★☆☆ 022043 8.331 The Profit\n",
      "★★★★☆ 191600 8.248 John Huston: The Man, the Movies, the Maverick\n",
      "★★★☆☆ 085411 8.248 The Three Stooges\n",
      "★★★★★ 102814 8.167 The Beach Boys: An American Band\n",
      "★★★☆☆ 004882 8.167 A Bullet for Pretty Boy\n",
      "★★★★★ 235932 8.167 Le grand Méliès\n",
      "★★★★☆ 004975 8.087 Love Is the Devil: Study for a Portrait of Francis Bacon\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"q\": query,\n",
    "    \"defType\": \"edismax\",\n",
    "    \"qf\": \"title_t description_t\",\n",
    "    \"pf\": \"title_t description_t\",\n",
    "    \"mm\": 2,\n",
    "    \"rq\": \"{!ltr model=myLambdaMARTModel reRankDocs=10 efi.query=\" + query + \"}\",\n",
    "    \"fl\": \"id,title_t,rating_f,score\",            \n",
    "    \"rows\": TOP_N * 2\n",
    "}\n",
    "params = urllib.parse.urlencode(payload, quote_via=urllib.parse.quote_plus)\n",
    "search_url = SOLR_URL + \"/select?\" + params\n",
    "resp = requests.get(search_url)\n",
    "resp_json = json.loads(resp.text)\n",
    "docs = resp_json[\"response\"][\"docs\"]\n",
    "render_results(docs, query, TOP_N * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
