{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training (no Index support)\n",
    "\n",
    "Command to train a LambdaMART model using RankLib.\n",
    "\n",
    "    cd <script_dir>\n",
    "    java -jar RankLib-2.10.jar \\\n",
    "        -train ../data/diy_features_train.txt \\\n",
    "        -test ../data/diy_features_test.txt \\\n",
    "        -validate ../data/diy_features_val.txt \\\n",
    "        -ranker 6 \\\n",
    "        -metric2t NDCG@10 \\\n",
    "        -metric2T ERR@10 \\\n",
    "        -norm zscore \\\n",
    "        -save ../data/diy_lambdamart_model.txt\n",
    "\t\n",
    "Output is as follows:\n",
    "\n",
    "\tDiscard orig. features\n",
    "\tTraining data:\t../data/diy_features_train.txt\n",
    "\tTest data:\t../data/diy_features_test.txt\n",
    "\tValidation data:\t../data/diy_features_val.txt\n",
    "\tFeature vector representation: Dense.\n",
    "\tRanking method:\tLambdaMART\n",
    "\tFeature description file:\tUnspecified. All features will be used.\n",
    "\tTrain metric:\tERR@10\n",
    "\tTest metric:\tERR@10\n",
    "\tHighest relevance label (to compute ERR): 4\n",
    "\tFeature normalization: No\n",
    "\tModel file: ../data/diy_lambdamart_model.txt\n",
    "\t\n",
    "\t[+] LambdaMART's Parameters:\n",
    "\tNo. of trees: 1000\n",
    "\tNo. of leaves: 10\n",
    "\tNo. of threshold candidates: 256\n",
    "\tMin leaf support: 1\n",
    "\tLearning rate: 0.1\n",
    "\tStop early: 100 rounds without performance gain on validation data\n",
    "\t\n",
    "\tReading feature file [../data/diy_features_train.txt]... [Done.]            \n",
    "\t(12 ranked lists, 1000 entries read)\n",
    "\tReading feature file [../data/diy_features_val.txt]... [Done.]            \n",
    "\t(3 ranked lists, 292 entries read)\n",
    "\tReading feature file [../data/diy_features_test.txt]... [Done.]            \n",
    "\t(5 ranked lists, 410 entries read)\n",
    "\tInitializing... [Done]\n",
    "\t---------------------------------\n",
    "\tTraining starts...\n",
    "\t---------------------------------\n",
    "\t#iter   | ERR@10-T  | ERR@10-V  | \n",
    "\t---------------------------------\n",
    "\t1       | 1.037     | 0.7195    | \n",
    "\t2       | 1.0371    | 0.6585    | \n",
    "\t3       | 1.0371    | 0.6746    | \n",
    "\t4       | 1.0371    | 0.6746    | \n",
    "\t5       | 1.0371    | 0.6746    | \n",
    "\t6       | 1.0371    | 0.6746    | \n",
    "\t7       | 1.0362    | 0.6585    | \n",
    "\t8       | 1.0362    | 0.6585    | \n",
    "\t9       | 1.0359    | 0.6585    | \n",
    "\t10      | 1.0371    | 0.6585    | \n",
    "\t11      | 1.0364    | 0.6585    | \n",
    "\t12      | 1.0365    | 0.6585    | \n",
    "\t13      | 1.0384    | 0.6585    | \n",
    "\t14      | 1.0285    | 0.6585    | \n",
    "\t15      | 1.0294    | 0.6585    | \n",
    "\t16      | 1.0286    | 0.6538    | \n",
    "\t17      | 1.0286    | 0.6538    | \n",
    "\t18      | 1.0284    | 0.6538    | \n",
    "\t19      | 1.0284    | 0.6538    | \n",
    "\t20      | 1.0284    | 0.6538    | \n",
    "\t21      | 1.0285    | 0.6538    | \n",
    "\t22      | 1.0285    | 0.6538    | \n",
    "\t23      | 1.0288    | 0.6538    | \n",
    "\t24      | 1.0705    | 0.6538    | \n",
    "\t25      | 1.0705    | 0.6538    | \n",
    "\t26      | 1.0705    | 0.6538    | \n",
    "\t27      | 1.0705    | 0.6538    | \n",
    "\t28      | 1.0705    | 0.6579    | \n",
    "\t29      | 1.0704    | 0.6538    | \n",
    "\t30      | 1.0704    | 0.6579    | \n",
    "\t31      | 1.0704    | 0.6579    | \n",
    "\t32      | 1.0706    | 0.6579    | \n",
    "\t33      | 1.0708    | 0.6712    | \n",
    "\t34      | 1.0709    | 0.6708    | \n",
    "\t35      | 1.0735    | 0.6864    | \n",
    "\t36      | 1.2409    | 0.6868    | \n",
    "\t37      | 1.2408    | 0.6712    | \n",
    "\t38      | 1.2393    | 0.6712    | \n",
    "\t39      | 1.1981    | 0.6712    | \n",
    "\t40      | 1.1981    | 0.6708    | \n",
    "\t41      | 1.1981    | 0.6708    | \n",
    "\t42      | 1.1981    | 0.6708    | \n",
    "\t43      | 1.1981    | 0.6708    | \n",
    "\t44      | 1.1984    | 0.6708    | \n",
    "\t45      | 1.1984    | 0.6708    | \n",
    "\t46      | 1.1984    | 0.6708    | \n",
    "\t47      | 1.1984    | 0.6708    | \n",
    "\t48      | 1.1985    | 0.6708    | \n",
    "\t49      | 1.2059    | 0.6708    | \n",
    "\t50      | 1.2409    | 0.6708    | \n",
    "\t51      | 1.26      | 0.6708    | \n",
    "\t52      | 1.26      | 0.6708    | \n",
    "\t53      | 1.26      | 0.6708    | \n",
    "\t54      | 1.2597    | 0.6708    | \n",
    "\t55      | 1.2597    | 0.6708    | \n",
    "\t56      | 1.2597    | 0.6708    | \n",
    "\t57      | 1.2597    | 0.6708    | \n",
    "\t58      | 1.2597    | 0.6708    | \n",
    "\t59      | 1.2597    | 0.6708    | \n",
    "\t60      | 1.2593    | 0.7164    | \n",
    "\t61      | 1.2593    | 0.7164    | \n",
    "\t62      | 1.2593    | 0.7164    | \n",
    "\t63      | 1.2593    | 0.7178    | \n",
    "\t64      | 1.2593    | 0.7178    | \n",
    "\t65      | 1.2593    | 0.7178    | \n",
    "\t66      | 1.2684    | 0.7337    | \n",
    "\t67      | 1.2751    | 0.7338    | \n",
    "\t68      | 1.0743    | 0.819     | \n",
    "\t69      | 0.7875    | 0.8668    | \n",
    "\t70      | 0.7875    | 0.8668    | \n",
    "\t71      | 0.7875    | 0.8668    | \n",
    "\t72      | 0.7875    | 0.8668    | \n",
    "\t73      | 0.7875    | 0.8668    | \n",
    "\t74      | 0.7875    | 0.8668    | \n",
    "\t75      | 0.7875    | 0.8668    | \n",
    "\t76      | 0.7875    | 0.8668    | \n",
    "\t77      | 0.7875    | 0.8668    | \n",
    "\t78      | 0.7875    | 0.8668    | \n",
    "\t79      | 0.7875    | 0.8668    | \n",
    "\t80      | 0.7875    | 0.8668    | \n",
    "\t81      | 0.7875    | 0.8668    | \n",
    "\t82      | 0.7875    | 0.8668    | \n",
    "\t83      | 0.7875    | 0.8668    | \n",
    "\t84      | 0.7875    | 0.8668    | \n",
    "\t85      | 0.7875    | 0.8668    | \n",
    "\t86      | 0.7875    | 0.8668    | \n",
    "\t87      | 0.7875    | 0.8668    | \n",
    "\t88      | 0.7875    | 0.8668    | \n",
    "\t89      | 0.7875    | 0.8668    | \n",
    "\t90      | 0.7875    | 0.8668    | \n",
    "\t91      | 0.7875    | 0.8668    | \n",
    "\t92      | 0.7875    | 0.8668    | \n",
    "\t93      | 0.7875    | 0.8668    | \n",
    "\t94      | 0.7875    | 0.8668    | \n",
    "\t95      | 0.7875    | 0.8668    | \n",
    "\t96      | 0.7875    | 0.8668    | \n",
    "\t97      | 0.7875    | 0.8668    | \n",
    "\t98      | 0.7875    | 0.8668    | \n",
    "\t99      | 0.7875    | 0.8668    | \n",
    "\t100     | 0.7875    | 0.8668    | \n",
    "\t101     | 0.7875    | 0.8668    | \n",
    "\t102     | 0.7875    | 0.8668    | \n",
    "\t103     | 0.7875    | 0.8668    | \n",
    "\t104     | 0.7875    | 0.8668    | \n",
    "\t105     | 0.7875    | 0.8668    | \n",
    "\t106     | 0.7875    | 0.8668    | \n",
    "\t107     | 0.7875    | 0.8668    | \n",
    "\t108     | 0.7875    | 0.8668    | \n",
    "\t109     | 0.7875    | 0.8668    | \n",
    "\t110     | 0.7875    | 0.8668    | \n",
    "\t111     | 0.7875    | 0.8668    | \n",
    "\t112     | 0.7875    | 0.8668    | \n",
    "\t113     | 0.7875    | 0.8668    | \n",
    "\t114     | 0.7875    | 0.8668    | \n",
    "\t115     | 0.7875    | 0.8668    | \n",
    "\t116     | 0.7875    | 0.8668    | \n",
    "\t117     | 0.7875    | 0.8668    | \n",
    "\t118     | 0.7875    | 0.8668    | \n",
    "\t119     | 0.7875    | 0.8668    | \n",
    "\t120     | 0.7875    | 0.8668    | \n",
    "\t121     | 0.7875    | 0.8668    | \n",
    "\t122     | 0.7875    | 0.8668    | \n",
    "\t123     | 0.7875    | 0.8668    | \n",
    "\t124     | 0.7875    | 0.8668    | \n",
    "\t125     | 0.7875    | 0.8668    | \n",
    "\t126     | 0.7875    | 0.8668    | \n",
    "\t127     | 0.7875    | 0.8668    | \n",
    "\t128     | 0.7875    | 0.8668    | \n",
    "\t129     | 0.7875    | 0.8668    | \n",
    "\t130     | 0.7875    | 0.8668    | \n",
    "\t131     | 0.7875    | 0.8668    | \n",
    "\t132     | 0.7875    | 0.8668    | \n",
    "\t133     | 0.7875    | 0.8668    | \n",
    "\t134     | 0.7875    | 0.8668    | \n",
    "\t135     | 0.7875    | 0.8668    | \n",
    "\t136     | 0.7875    | 0.8668    | \n",
    "\t137     | 0.7875    | 0.8668    | \n",
    "\t138     | 0.7875    | 0.8668    | \n",
    "\t139     | 0.7875    | 0.8668    | \n",
    "\t140     | 0.7875    | 0.8668    | \n",
    "\t141     | 0.7875    | 0.8668    | \n",
    "\t142     | 0.7875    | 0.8668    | \n",
    "\t143     | 0.7875    | 0.8668    | \n",
    "\t144     | 0.7875    | 0.8668    | \n",
    "\t145     | 0.7875    | 0.8668    | \n",
    "\t146     | 0.7875    | 0.8668    | \n",
    "\t147     | 0.7875    | 0.8668    | \n",
    "\t148     | 0.7875    | 0.8668    | \n",
    "\t149     | 0.7875    | 0.8668    | \n",
    "\t150     | 0.7875    | 0.8668    | \n",
    "\t151     | 0.7875    | 0.8668    | \n",
    "\t152     | 0.7875    | 0.8668    | \n",
    "\t153     | 0.7875    | 0.8668    | \n",
    "\t154     | 0.7875    | 0.8668    | \n",
    "\t155     | 0.7875    | 0.8668    | \n",
    "\t156     | 0.7875    | 0.8668    | \n",
    "\t157     | 0.7875    | 0.8668    | \n",
    "\t158     | 0.7875    | 0.8668    | \n",
    "\t159     | 0.7875    | 0.8668    | \n",
    "\t160     | 0.7875    | 0.8668    | \n",
    "\t161     | 0.7875    | 0.8668    | \n",
    "\t162     | 0.7875    | 0.8668    | \n",
    "\t163     | 0.7875    | 0.8668    | \n",
    "\t164     | 0.7875    | 0.8668    | \n",
    "\t165     | 0.7875    | 0.8668    | \n",
    "\t166     | 0.7875    | 0.8668    | \n",
    "\t167     | 0.7875    | 0.8668    | \n",
    "\t168     | 0.7875    | 0.8668    | \n",
    "\t169     | 0.7875    | 0.8668    | \n",
    "\t170     | 0.7875    | 0.8668    | \n",
    "\t---------------------------------\n",
    "\tFinished sucessfully.\n",
    "\tERR@10 on training data: 0.7875\n",
    "\tERR@10 on validation data: 0.8668\n",
    "\t---------------------------------\n",
    "\tERR@10 on test data: 0.9169\n",
    "\t\n",
    "\tModel saved to: ../data/diy_lambdamart_model.txt\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
