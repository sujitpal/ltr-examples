{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training (Elasticsearch LTR)\n",
    "\n",
    "We train a LambdaMart model using [RankLib](https://sourceforge.net/p/lemur/wiki/RankLib%20How%20to%20use/) and upload the trained model to Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPTS_DIR = \"../../scripts\"\n",
    "MODEL_FILE = os.path.join(SCRIPTS_DIR, \"es_lambdamart_model.txt\")\n",
    "\n",
    "ES_URL = \"http://localhost:9200/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with RankLib\n",
    "\n",
    "Command is as follows:\n",
    "\n",
    "    java -jar RankLib-2.1-patched.jar \\\n",
    "        -train ../data/tmdb-dataset/es_features_train.txt \\\n",
    "        -test ../data/tmdb-dataset/es_features_test.txt \\\n",
    "        -validate ../data/tmdb-dataset/es_features_val.txt \\\n",
    "        -ranker 6 \\\n",
    "        -metric2t NDCG@10 \\\n",
    "        -metric2T ERR@10 \\\n",
    "        -save ../data/tmdb-dataset/solr_lambdamart_model.txt\n",
    "\n",
    "Console output is shown below:\n",
    "\n",
    "\t[+] General Parameters:\n",
    "\tTraining data:\t../data/tmdb-dataset/es_features_train.txt\n",
    "\tTest data:\t../data/tmdb-dataset/es_features_test.txt\n",
    "\tValidation data:\t../data/tmdb-dataset/es_features_val.txt\n",
    "\tFeature vector representation: Dense.\n",
    "\tRanking method:\tLambdaMART\n",
    "\tFeature description file:\tUnspecified. All features will be used.\n",
    "\tTrain metric:\tNDCG@10\n",
    "\tTest metric:\tERR@10\n",
    "\tHighest relevance label (to compute ERR): 4\n",
    "\tFeature normalization: No\n",
    "\tModel file: ../scripts/es_lambdamart_model.txt\n",
    "\t\n",
    "\t[+] LambdaMART's Parameters:\n",
    "\tNo. of trees: 1000\n",
    "\tNo. of leaves: 10\n",
    "\tNo. of threshold candidates: 256\n",
    "\tLearning rate: 0.1\n",
    "\tStop early: 100 rounds without performance gain on validation data\n",
    "\t\n",
    "\tReading feature file [../data/tmdb-dataset/es_features_train.txt]... [Done.]            \n",
    "\t(12 ranked lists, 1200 entries read)\n",
    "\tReading feature file [../data/tmdb-dataset/es_features_val.txt]... [Done.]            \n",
    "\t(3 ranked lists, 300 entries read)\n",
    "\tReading feature file [../data/tmdb-dataset/es_features_test.txt]... [Done.]            \n",
    "\t(5 ranked lists, 480 entries read)\n",
    "\tInitializing... [Done]\n",
    "\t---------------------------------\n",
    "\tTraining starts...\n",
    "\t---------------------------------\n",
    "\t#iter   | NDCG@10-T | NDCG@10-V | \n",
    "\t---------------------------------\n",
    "\t1       | 0.844     | 0.844     | \n",
    "\t2       | 0.8652    | 0.8652    | \n",
    "\t3       | 0.8652    | 0.8652    | \n",
    "\t4       | 0.8652    | 0.8652    | \n",
    "\t5       | 0.8652    | 0.8652    | \n",
    "\t6       | 0.8652    | 0.8652    | \n",
    "\t7       | 0.8652    | 0.8652    | \n",
    "\t8       | 0.8652    | 0.8652    | \n",
    "\t9       | 0.8652    | 0.8652    | \n",
    "\t10      | 0.8652    | 0.8652    | \n",
    "\t11      | 0.8652    | 0.8652    | \n",
    "\t12      | 0.8652    | 0.8652    | \n",
    "\t13      | 0.8997    | 0.8997    | \n",
    "\t14      | 0.8997    | 0.8997    | \n",
    "\t15      | 0.9011    | 0.9011    | \n",
    "\t16      | 0.9011    | 0.9011    | \n",
    "\t17      | 0.9028    | 0.9028    | \n",
    "\t18      | 0.9028    | 0.9028    | \n",
    "\t19      | 0.9373    | 0.9373    | \n",
    "\t20      | 0.9373    | 0.9373    | \n",
    "\t21      | 0.9373    | 0.9373    | \n",
    "\t22      | 0.9435    | 0.9435    | \n",
    "\t23      | 0.9607    | 0.9607    | \n",
    "\t24      | 0.9607    | 0.9607    | \n",
    "\t25      | 0.978     | 0.978     | \n",
    "\t26      | 0.9801    | 0.9801    | \n",
    "\t27      | 0.9865    | 0.9865    | \n",
    "\t28      | 0.9917    | 0.9917    | \n",
    "\t29      | 0.9917    | 0.9917    | \n",
    "\t30      | 0.9917    | 0.9917    | \n",
    "\t31      | 0.9917    | 0.9917    | \n",
    "\t32      | 0.9917    | 0.9917    | \n",
    "\t33      | 1.0       | 1.0       | \n",
    "\t34      | 1.0       | 1.0       | \n",
    "\t35      | 1.0       | 1.0       | \n",
    "\t36      | 1.0       | 1.0       | \n",
    "\t37      | 1.0       | 1.0       | \n",
    "\t38      | 1.0       | 1.0       | \n",
    "\t39      | 1.0       | 1.0       | \n",
    "\t40      | 1.0       | 1.0       | \n",
    "\t41      | 1.0       | 1.0       | \n",
    "\t42      | 1.0       | 1.0       | \n",
    "\t43      | 1.0       | 1.0       | \n",
    "\t44      | 1.0       | 1.0       | \n",
    "\t45      | 1.0       | 1.0       | \n",
    "\t46      | 1.0       | 1.0       | \n",
    "\t47      | 1.0       | 1.0       | \n",
    "\t48      | 1.0       | 1.0       | \n",
    "\t49      | 1.0       | 1.0       | \n",
    "\t50      | 1.0       | 1.0       | \n",
    "\t51      | 1.0       | 1.0       | \n",
    "\t52      | 1.0       | 1.0       | \n",
    "\t53      | 1.0       | 1.0       | \n",
    "\t54      | 1.0       | 1.0       | \n",
    "\t55      | 1.0       | 1.0       | \n",
    "\t56      | 1.0       | 1.0       | \n",
    "\t57      | 1.0       | 1.0       | \n",
    "\t58      | 1.0       | 1.0       | \n",
    "\t59      | 1.0       | 1.0       | \n",
    "\t60      | 1.0       | 1.0       | \n",
    "\t61      | 1.0       | 1.0       | \n",
    "\t62      | 1.0       | 1.0       | \n",
    "\t63      | 1.0       | 1.0       | \n",
    "\t64      | 1.0       | 1.0       | \n",
    "\t65      | 1.0       | 1.0       | \n",
    "\t66      | 1.0       | 1.0       | \n",
    "\t67      | 1.0       | 1.0       | \n",
    "\t68      | 1.0       | 1.0       | \n",
    "\t69      | 1.0       | 1.0       | \n",
    "\t70      | 1.0       | 1.0       | \n",
    "\t71      | 1.0       | 1.0       | \n",
    "\t72      | 1.0       | 1.0       | \n",
    "\t73      | 1.0       | 1.0       | \n",
    "\t74      | 1.0       | 1.0       | \n",
    "\t75      | 1.0       | 1.0       | \n",
    "\t76      | 1.0       | 1.0       | \n",
    "\t77      | 1.0       | 1.0       | \n",
    "\t78      | 1.0       | 1.0       | \n",
    "\t79      | 1.0       | 1.0       | \n",
    "\t80      | 1.0       | 1.0       | \n",
    "\t81      | 1.0       | 1.0       | \n",
    "\t82      | 1.0       | 1.0       | \n",
    "\t83      | 1.0       | 1.0       | \n",
    "\t84      | 1.0       | 1.0       | \n",
    "\t85      | 1.0       | 1.0       | \n",
    "\t86      | 1.0       | 1.0       | \n",
    "\t87      | 1.0       | 1.0       | \n",
    "\t88      | 1.0       | 1.0       | \n",
    "\t89      | 1.0       | 1.0       | \n",
    "\t90      | 1.0       | 1.0       | \n",
    "\t91      | 1.0       | 1.0       | \n",
    "\t92      | 1.0       | 1.0       | \n",
    "\t93      | 1.0       | 1.0       | \n",
    "\t94      | 1.0       | 1.0       | \n",
    "\t95      | 1.0       | 1.0       | \n",
    "\t96      | 1.0       | 1.0       | \n",
    "\t97      | 1.0       | 1.0       | \n",
    "\t98      | 1.0       | 1.0       | \n",
    "\t99      | 1.0       | 1.0       | \n",
    "\t100     | 1.0       | 1.0       | \n",
    "\t101     | 1.0       | 1.0       | \n",
    "\t102     | 1.0       | 1.0       | \n",
    "\t103     | 1.0       | 1.0       | \n",
    "\t104     | 1.0       | 1.0       | \n",
    "\t105     | 1.0       | 1.0       | \n",
    "\t106     | 1.0       | 1.0       | \n",
    "\t107     | 1.0       | 1.0       | \n",
    "\t108     | 1.0       | 1.0       | \n",
    "\t109     | 1.0       | 1.0       | \n",
    "\t110     | 1.0       | 1.0       | \n",
    "\t111     | 1.0       | 1.0       | \n",
    "\t112     | 1.0       | 1.0       | \n",
    "\t113     | 1.0       | 1.0       | \n",
    "\t114     | 1.0       | 1.0       | \n",
    "\t115     | 1.0       | 1.0       | \n",
    "\t116     | 1.0       | 1.0       | \n",
    "\t117     | 1.0       | 1.0       | \n",
    "\t118     | 1.0       | 1.0       | \n",
    "\t119     | 1.0       | 1.0       | \n",
    "\t120     | 1.0       | 1.0       | \n",
    "\t121     | 1.0       | 1.0       | \n",
    "\t122     | 1.0       | 1.0       | \n",
    "\t123     | 1.0       | 1.0       | \n",
    "\t124     | 1.0       | 1.0       | \n",
    "\t125     | 1.0       | 1.0       | \n",
    "\t126     | 1.0       | 1.0       | \n",
    "\t127     | 1.0       | 1.0       | \n",
    "\t128     | 1.0       | 1.0       | \n",
    "\t129     | 1.0       | 1.0       | \n",
    "\t130     | 1.0       | 1.0       | \n",
    "\t131     | 1.0       | 1.0       | \n",
    "\t132     | 1.0       | 1.0       | \n",
    "\t133     | 1.0       | 1.0       | \n",
    "\t134     | 1.0       | 1.0       | \n",
    "\t---------------------------------\n",
    "\tFinished sucessfully.\n",
    "\tNDCG@10 on training data: 1.0\n",
    "\tNDCG@10 on validation data: 1.0\n",
    "\t---------------------------------\n",
    "\tERR@10 on test data: 2.1856\n",
    "\t\n",
    "\tModel saved to: ../scripts/es_lambdamart_model.txt\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_index\":\".ltrstore\",\"_type\":\"store\",\"_id\":\"model-es_lambdamart_model\",\"_version\":1,\"result\":\"created\",\"forced_refresh\":true,\"_shards\":{\"total\":1,\"successful\":1,\"failed\":0},\"_seq_no\":1,\"_primary_term\":1}\n"
     ]
    }
   ],
   "source": [
    "model_def = None\n",
    "with open(MODEL_FILE, \"r\") as model_file:\n",
    "    model_def = model_file.read()\n",
    "\n",
    "data = {\n",
    "    \"model\": {\n",
    "        \"name\": \"es_lambdamart_model\",\n",
    "        \"model\": {\n",
    "            \"type\": \"model/ranklib\",\n",
    "            \"definition\": model_def\n",
    "        }\n",
    "    }\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "resp = requests.post(ES_URL + \"_ltr/_featureset/myFeatures/_createmodel\", \n",
    "                     headers=headers, data=json.dumps(data))\n",
    "print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
